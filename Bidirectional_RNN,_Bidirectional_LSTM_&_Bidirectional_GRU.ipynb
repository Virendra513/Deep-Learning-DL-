{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDKZY/6iO70QTu81i48BII"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Bidirectional RNN**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Bidirectional Recurrent Neural Networks (BiRNNs) are a type of recurrent neural network architecture that processes the input sequence in both forward and backward directions. This allows the network to capture information from past and future contexts simultaneously. Bidirectional RNNs are particularly useful for tasks where understanding the context in both directions is important, such as natural language processing.\n",
        "\n",
        "Applications:\n",
        "\n",
        "\n",
        "1.   Named Entity Recognition(NER)\n",
        "2.   Part of Speech Tagging(PoS)\n",
        "3.   Machine Translation\n",
        "4.   Time Series Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "cXjiRwikKsqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "99Rc84ppFr9v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, SimpleRNN, Dense, LSTM, GRU, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ImDb dataset\n",
        "num_words=10000\n",
        "(x_train, y_train), (x_test, y_test)= imdb.load_data(num_words=num_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLDmbz5fGGVz",
        "outputId": "4cfe9dbf-44b7-4ed4-ffdc-789c859445ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to have the same length\n",
        "maxlen=100\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "RjwrgCozGbp1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Bidirectional RNN model\n",
        "embedding_dim=32 # Dimension of embedding layer\n",
        "model= Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=embedding_dim, input_length= maxlen),\n",
        "    Bidirectional(SimpleRNN(5)), # 5 RNN units\n",
        "    Dense(1, activation='sigmoid') # Binary classification (positive/nrgative)\n",
        "])"
      ],
      "metadata": {
        "id": "0nCG0ifjHjjb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Nb7bRCJ7vB",
        "outputId": "f6a8ef28-aea4-4b0b-f5a0-225f3684c6b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 10)                380       \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320391 (1.22 MB)\n",
            "Trainable params: 320391 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lPV-DXhEJWsU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bidirectional LSTM**"
      ],
      "metadata": {
        "id": "QbpYHzOELAxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Bidirectional RNN model\n",
        "embedding_dim=32 # Dimension of embedding layer\n",
        "model= Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=embedding_dim, input_length= maxlen),\n",
        "    Bidirectional(LSTM(5)), # 5 RNN units\n",
        "    Dense(1, activation='sigmoid') # Binary classification (positive/nrgative)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwQIVOErLDIM",
        "outputId": "90cfe034-0870-45c0-b1c3-89081443e17b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 10)                1520      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321531 (1.23 MB)\n",
            "Trainable params: 321531 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bidirectional GRU**"
      ],
      "metadata": {
        "id": "eR7QbNkTMnly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Bidirectional RNN model\n",
        "embedding_dim=32 # Dimension of embedding layer\n",
        "model= Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=embedding_dim, input_length= maxlen),\n",
        "    Bidirectional(GRU(5)), # 5 RNN units\n",
        "    Dense(1, activation='sigmoid') # Binary classification (positive/nrgative)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvOq9FjcMtKc",
        "outputId": "e9a93cf6-63b1-4a79-ca56-be6c8aea3bb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 10)                1170      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321181 (1.23 MB)\n",
            "Trainable params: 321181 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applications:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Named Entity Recognition (NER): BiRNNs are effective for identifying entities in text data by considering the context from both directions.\n",
        "\n",
        "2. Sentiment Analysis: Understanding the sentiment of a sentence or document benefits from capturing contextual information in both directions.\n",
        "\n",
        "3. Machine Translation: In tasks involving translation, BiRNNs can aid in understanding the source and target languages' context."
      ],
      "metadata": {
        "id": "pCStljUemrrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limitations:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. Computational Complexity:\n",
        "\n",
        "Bidirectional processing effectively doubles the computational cost compared to unidirectional RNNs, as both forward and backward passes need to be performed. This increased complexity can make training and inference more resource-intensive.\n",
        "\n",
        "2. Memory Requirements:\n",
        "\n",
        "Bidirectional models tend to have higher memory requirements due to the need to store information from both directions. This can be a limitation, especially when dealing with large datasets or deploying models on resource-constrained devices.\n",
        "Sequential Processing:\n",
        "\n",
        "While BiRNNs excel in capturing sequential dependencies, they may struggle with tasks where long-term dependencies are crucial. More advanced architectures, such as Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU), are often preferred for handling long-range dependencies.\n",
        "\n",
        "3. Difficulty in Real-Time Applications:\n",
        "\n",
        "In real-time applications, the bidirectional nature of the model can pose challenges. For instance, in scenarios where predictions need to be made as soon as new data becomes available, waiting for both past and future information might not be feasible.\n",
        "\n",
        "4. Lack of Causality:\n",
        "\n",
        "BiRNNs process information from both directions simultaneously, which may not align with the concept of causality in certain applications. In some scenarios, the future should not influence predictions in the past.\n",
        "\n",
        "5. Training Challenges:\n",
        "\n",
        "Training BiRNNs can be more challenging than training unidirectional RNNs. The bidirectional nature may require careful consideration of optimization strategies and learning rates to ensure stable convergence during training.\n",
        "\n",
        "6. Interpretability:\n",
        "\n",
        "Understanding the contribution of specific elements in the input sequence to the final prediction can be more complex in a bidirectional model. Interpreting the significance of features from both directions might be challenging.\n",
        "\n",
        "7. Limited Effectiveness in Some Cases:\n",
        "\n",
        "In certain tasks or datasets, bidirectional processing may not always provide significant improvements. In cases where the information from one direction is sufficient, the added complexity may not justify the benefits."
      ],
      "metadata": {
        "id": "3GEjkhw0m92-"
      }
    }
  ]
}